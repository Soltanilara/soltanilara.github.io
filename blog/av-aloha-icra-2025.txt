3:I[9275,[],""]
5:I[1343,[],""]
6:I[4858,["699","static/chunks/8e1d74a4-561e044f358a70a9.js","173","static/chunks/173-1b457355cc0f6eb8.js","231","static/chunks/231-75217c32967b80fc.js","521","static/chunks/521-a3cc0266cc1077a1.js","443","static/chunks/443-ccb272207b22f4bd.js","185","static/chunks/app/layout-e9f41310a2e3199e.js"],"ThemeProvider"]
7:I[9736,["699","static/chunks/8e1d74a4-561e044f358a70a9.js","173","static/chunks/173-1b457355cc0f6eb8.js","231","static/chunks/231-75217c32967b80fc.js","521","static/chunks/521-a3cc0266cc1077a1.js","443","static/chunks/443-ccb272207b22f4bd.js","185","static/chunks/app/layout-e9f41310a2e3199e.js"],"TooltipProvider"]
8:I[1807,["699","static/chunks/8e1d74a4-561e044f358a70a9.js","173","static/chunks/173-1b457355cc0f6eb8.js","231","static/chunks/231-75217c32967b80fc.js","521","static/chunks/521-a3cc0266cc1077a1.js","443","static/chunks/443-ccb272207b22f4bd.js","185","static/chunks/app/layout-e9f41310a2e3199e.js"],"default"]
9:I[231,["173","static/chunks/173-1b457355cc0f6eb8.js","231","static/chunks/231-75217c32967b80fc.js","308","static/chunks/app/blog/%5Bslug%5D/page-21d121c6a2735f65.js"],""]
4:["slug","av-aloha-icra-2025","d"]
0:["QYuCXi6nL7r3-tVVxXO2h",[[["",{"children":["blog",{"children":[["slug","av-aloha-icra-2025","d"],{"children":["__PAGE__?{\"slug\":\"av-aloha-icra-2025\"}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["blog",{"children":[["slug","av-aloha-icra-2025","d"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"en","suppressHydrationWarning":true,"className":"__className_3a0388","children":["$","body",null,{"className":"antialiased bg-gray-50","children":["$","$L6",null,{"attribute":"class","defaultTheme":"light","children":["$","$L7",null,{"delayDuration":0,"children":["$","div",null,{"className":"min-h-screen p-3","children":["$","div",null,{"className":"fixed inset-3 flex rounded-xl bg-white shadow-sm","children":[["$","$L8",null,{}],["$","main",null,{"className":"flex-1 overflow-auto","children":["$","div",null,{"className":"w-full","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","main",null,{"className":"flex flex-col min-h-screen","children":["$","div",null,{"className":"flex-grow flex items-center justify-center px-6 md:px-10","children":["$","div",null,{"className":"max-w-md mx-auto text-center","children":[["$","h1",null,{"className":"text-4xl font-medium mb-4","children":"404"}],["$","h2",null,{"className":"text-xl mb-4","children":"Page Not Found"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"The page you're looking for doesn't exist or has been moved."}],["$","$L9",null,{"href":"/","className":"inline-flex items-center text-sm bg-black text-white px-6 py-3 rounded-full hover:bg-gray-800 transition-colors","children":"Return Home"}]]}]}]}],"notFoundStyles":[],"styles":null}]}]}]]}]}]}]}]}]}],null],null],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/ae2e9ad0d33ab6d9.css","precedence":"next","crossOrigin":"$undefined"}]],"$La"]]]]
b:I[8173,["173","static/chunks/173-1b457355cc0f6eb8.js","231","static/chunks/231-75217c32967b80fc.js","308","static/chunks/app/blog/%5Bslug%5D/page-21d121c6a2735f65.js"],"Image"]
c:T1312,<h1>AV-ALOHA: Pioneering Active Vision in Robotic Manipulation</h1>
<p>We are thrilled to announce that our research paper "Active Vision Might Be All You Need" has been accepted for presentation at ICRA 2025. This work represents a significant milestone in our ongoing research at LARA Lab, where we're advancing the capabilities of robotic systems through innovative active vision approaches.</p>
<h2>The Challenge of "Simple" Tasks</h2>
<p>What comes naturally to humans often proves surprisingly complex for robots. As Dr. Soltani notes, "Some of the things that we take for granted as humans are so simple that we don't even pay attention to how we achieve them. We have evolved over millions of years to achieve certain capabilities. When you start to think in terms of robotics, you realize that they're quite complex."</p>
<p>Consider a task as straightforward as threading a needle or pouring liquid from one test tube to another. Humans instinctively adjust their viewpoint to get the best angle, a skill that has proven notoriously difficult to program into robots – until now.</p>
<h2>Active Vision: Teaching Robots to See Like Humans</h2>
<p>Our research introduces AV-ALOHA, a groundbreaking system that enables robots to actively control their "point of view." Unlike traditional fixed-camera systems, AV-ALOHA can dynamically adjust its perspective to gather the most relevant information for any given task.</p>
<p>The system comprises three key components:</p>
<ul>
<li>Two robotic arms for manipulation tasks</li>
<li>A dedicated 7-DoF camera arm for active vision</li>
<li>A VR-based control interface for intuitive human demonstration</li>
</ul>
<p>Through this setup, operators can control the manipulation arms while simultaneously adjusting the camera's viewpoint using natural head movements, all while receiving real-time visual feedback through the VR headset.</p>
<h2>From Demonstration to Autonomy</h2>
<p>Our research goes beyond mere teleoperation. Through imitation learning, AV-ALOHA learns not just how to manipulate objects, but also how to position its camera for optimal task performance. We conducted extensive experiments across five simulation tasks and one real-world scenario, each designed to test different aspects of active vision:</p>
<ul>
<li>Peg insertion</li>
<li>Slot insertion</li>
<li>Hook package manipulation</li>
<li>Test tube pouring</li>
<li>Thread needle insertion</li>
<li>Occluded insertion (real-world)</li>
</ul>
<p>The results were compelling: in scenarios where perspective matters most – particularly the thread needle test and occluded insertion – AV-ALOHA significantly outperformed systems with multiple fixed cameras.</p>
<h2>Unexpected Insights</h2>
<p>One fascinating discovery was that in tasks where varying perspectives weren't critical, the active vision system performed just as well as traditional setups with multiple fixed cameras. This suggests that a single, well-positioned camera might be sufficient for many tasks, potentially simplifying future robotic systems.</p>
<h2>Looking Forward: The Next Phase</h2>
<p>Our acceptance to ICRA 2025 marks not an endpoint but a milestone in ongoing research. We're currently exploring several intriguing questions:</p>
<ul>
<li>How do robots balance camera movement with manipulation tasks?</li>
<li>Should perspective adjustment precede or coincide with manipulation?</li>
<li>Can we optimize head movement to mirror human behavior?</li>
</ul>
<p>As Dr. Soltani explains, "We think that in more complex scenarios, most likely, we don't want to keep moving our heads while trying to complete a sensitive task with our hands." This insight is driving our next research phase, where we'll explore penalizing excessive head movement during precise manipulation tasks.</p>
<h2>The Research Team</h2>
<p>This breakthrough represents a collaborative effort between UC Berkeley and UC Davis researchers:</p>
<ul>
<li>Ian Chuang* (UC Berkeley)</li>
<li>Andrew Lee* (UC Davis)</li>
<li>Dechen Gao (UC Davis)</li>
<li>M-Mahdi Naddaf-Sh (UC Davis)</li>
<li>Iman Soltani (UC Davis)</li>
</ul>
<p>*Equal contribution</p>
<h2>Join Us at ICRA 2025</h2>
<p>We look forward to presenting these findings at ICRA 2025, where we'll demonstrate live system operations and discuss future applications in industrial automation, surgical robotics, and human-robot collaboration.</p>
<h2>Learn More</h2>
<p>Explore our research in detail:</p>
<ul>
<li><a href="https://soltanilara.github.io/av-aloha/">Project Website</a></li>
<li><a href="https://arxiv.org/abs/2409.17435">Research Paper</a></li>
<li><a href="https://soltanilara.github.io/av-aloha/">Technical Demonstrations</a></li>
</ul>
<hr>
<p><em>For collaboration inquiries or more information about our research, please contact us. We look forward to engaging with the robotics research community at ICRA 2025.</em></p>2:["$","section",null,{"className":"max-w-4xl mx-auto px-6","children":[["$","script",null,{"type":"application/ld+json","suppressHydrationWarning":true,"dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BlogPosting\",\"headline\":\"AV-ALOHA: Advancing Active Vision in Robotics - Accepted to ICRA 2025\",\"datePublished\":\"2025-04-22\",\"dateModified\":\"2025-04-22\",\"description\":\"LARA Lab's groundbreaking research on active vision in robotic manipulation has been accepted to ICRA 2025\",\"image\":\"https://dillion.io/og?title=AV-ALOHA: Advancing Active Vision in Robotics - Accepted to ICRA 2025\",\"url\":\"https://dillion.io/blog/av-aloha-icra-2025\",\"author\":{\"@type\":\"Person\",\"name\":\"LARA\"}}"}}],["$","div",null,{"className":"py-6","children":["$","$L9",null,{"href":"/blog","className":"inline-flex items-center text-[15px] text-gray-600 hover:text-gray-900","children":[["$","svg",null,{"className":"mr-2 w-4 h-4","fill":"none","viewBox":"0 0 24 24","stroke":"currentColor","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","strokeWidth":2,"d":"M10 19l-7-7m0 0l7-7m-7 7h18"}]}],"Back to all posts"]}]}],["$","div",null,{"className":"pt-8 pb-10 max-w-3xl mx-auto text-center","children":[["$","div",null,{"className":"mb-3 flex items-center justify-center","children":[["$","span",null,{"className":"text-sm text-gray-500","children":"April 22, 2025 (7mo ago)"}],"$undefined"]}],["$","h1",null,{"className":"text-4xl md:text-5xl font-medium tracking-tight mb-6","children":"AV-ALOHA: Advancing Active Vision in Robotics - Accepted to ICRA 2025"}],["$","p",null,{"className":"text-[17px] text-gray-600 max-w-2xl mx-auto","children":"LARA Lab's groundbreaking research on active vision in robotic manipulation has been accepted to ICRA 2025"}]]}],["$","div",null,{"className":"mb-12","children":["$","$Lb",null,{"src":"/h0.jpg","alt":"AV-ALOHA: Advancing Active Vision in Robotics - Accepted to ICRA 2025","width":1200,"height":630,"className":"w-full h-auto rounded-lg"}]}],false,["$","article",null,{"className":"max-w-3xl mx-auto","children":["$","div",null,{"className":"prose prose-gray max-w-none text-[15px]","dangerouslySetInnerHTML":{"__html":"$c"}}]}],["$","div",null,{"className":"max-w-3xl mx-auto mt-12 pt-8 border-t border-gray-100","children":[["$","h2",null,{"className":"text-xl font-medium mb-4","children":"Authors"}],["$","div",null,{"className":"flex items-center","children":[["$","div",null,{"className":"w-12 h-12 rounded-full bg-gray-200 mr-4"}],["$","div",null,{"children":[["$","h3",null,{"className":"text-base font-medium","children":"LARA Lab"}],["$","p",null,{"className":"text-[15px] text-gray-600","children":"The Laboratory for AI, Robotics, and Automation at UC Davis"}]]}]]}]]}],["$","div",null,{"className":"max-w-3xl mx-auto mt-16 pt-8 border-t border-gray-100","children":[["$","h2",null,{"className":"text-xl font-medium mb-6","children":"Related Research"}],["$","div",null,{"className":"space-y-4","children":["$","p",null,{"className":"text-[15px] text-gray-600","children":"Explore more research from our lab"}]}]]}],["$","footer",null,{"className":"max-w-3xl mx-auto mt-16 pt-8 pb-16 border-t border-gray-100 text-sm text-gray-600","children":[["$","p",null,{"children":"University of California, Davis"}],["$","p",null,{"children":"One Shields Avenue, Davis, CA 95616"}],["$","p",null,{"className":"mt-4","children":"© The Regents of the University of California, Davis campus."}]]}]]}]
a:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"AV-ALOHA: Advancing Active Vision in Robotics - Accepted to ICRA 2025 | LARA"}],["$","meta","3",{"name":"description","content":"LARA Lab's groundbreaking research on active vision in robotic manipulation has been accepted to ICRA 2025"}],["$","meta","4",{"name":"robots","content":"index, follow"}],["$","meta","5",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","meta","6",{"property":"og:title","content":"AV-ALOHA: Advancing Active Vision in Robotics - Accepted to ICRA 2025"}],["$","meta","7",{"property":"og:description","content":"LARA Lab's groundbreaking research on active vision in robotic manipulation has been accepted to ICRA 2025"}],["$","meta","8",{"property":"og:url","content":"https://dillion.io/blog/av-aloha-icra-2025"}],["$","meta","9",{"property":"og:image","content":"https://dillion.io/h0.jpg"}],["$","meta","10",{"property":"og:type","content":"article"}],["$","meta","11",{"property":"article:published_time","content":"2025-04-22"}],["$","meta","12",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","13",{"name":"twitter:title","content":"AV-ALOHA: Advancing Active Vision in Robotics - Accepted to ICRA 2025"}],["$","meta","14",{"name":"twitter:description","content":"LARA Lab's groundbreaking research on active vision in robotic manipulation has been accepted to ICRA 2025"}],["$","meta","15",{"name":"twitter:image","content":"https://dillion.io/h0.jpg"}],["$","link","16",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}],["$","meta","17",{"name":"next-size-adjust"}]]
1:null
